---
title: "Final Project RFS"
author: "Jerome Goh"
date: "`r Sys.Date()`"
output: html_document
---

## Data Cleaning Plan


> Re-factor qualitative variables, namely:
- Drive System Code
- Tested Transmission Type
- Fuel Type Cd
- Test Procedure Cd

> Tackle FE measured by MPG
FE DOES DEPEND ON THE TYPE OF TESTING. GAS EMISSIONS ALSO DIFFER BASED ON TYPE OF TESTING

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First install the following packages...

OR

Load workspace image titled "impute.RData", to view all generated variables in global environment

## Data Cleaning

```{r echo=FALSE, warning = FALSE}
 
library(readxl) # to parse Excel files

mydata <- read_excel("proj_data.xlsx")
# attach(car_test)

# Remove redundant/repeated columns, like identifiers

car_test <- mydata[, !names(mydata) %in% c("Test Vehicle ID", "Actual Tested Testgroup", "Test Veh Configuration #", "Engine Code", "Shift Indicator Light Use Cd", "Shift Indicator Light Use Desc", "Test Number", "ADFE Test Number", "Tested Transmission Type Code", "Transmission Overdrive Code", "Veh Mfr Code", "Model Year", "Represented Test Veh Make", "Averaging Group ID", "Averaging Group ID", "Averaging Weighting Factor", "Averaging Method Cd", "Averaging Method Desc","ADFE Total Road Load HP", "ADFE Equiv. Test Weight (lbs.)", "ADFE N/V Ratio", "Drive System Code", "Test Procedure Cd", "Police - Emergency Vehicle?", "ADFE", "Analytically Derived FE?", "FE Bag 1", "FE Bag 2", "FE Bag 4", "FE Bag 3", "Aftertreatment Device Cd", "Test Fuel Type Cd")]


colnames(car_test) <- make.names(colnames(car_test), unique = TRUE)

# Rename column names for easier calling
names(car_test)[names(car_test) == "Test.Fuel.Type.Description"] <- "fuel.type"
names(car_test)[names(car_test) == "Transmission.Lockup."] <- "trans.lockup"
names(car_test)[names(car_test) == "Transmission.Overdrive.Desc"] <- "trans.overdrive"
names(car_test)[names(car_test) == "Test.Procedure.Description"] <- "test.procedure"
names(car_test)[names(car_test) == "Test.Category"] <- "test.category"
names(car_test)[names(car_test) == "Tested.Transmission.Type"] <- "trans"
names(car_test)[names(car_test) == "Drive.System.Description"] <- "drive.sys"
names(car_test)[names(car_test) == "Aftertreatment.Device.Desc"] <- "aftertreatment"

names(car_test)[names(car_test) == "THC..g.mi."] <- "THC"
names(car_test)[names(car_test) == "NOx..g.mi."] <- "NOx"
names(car_test)[names(car_test) == "CO..g.mi."] <- "CO"
names(car_test)[names(car_test) ==  "CO2..g.mi."] <- "CO2"
names(car_test)[names(car_test) == "PM..g.mi."] <- "PM"
names(car_test)[names(car_test) == "CH4..g.mi."] <- "CH4"
names(car_test)[names(car_test) == "N2O..g.mi."] <- "N2O"

print(colnames(car_test))

# Factoring our categorical variables
factors <- c("fuel.type", "test.procedure", "test.category", "trans", "drive.sys", "trans.lockup", 
             "trans.overdrive","aftertreatment","Vehicle.Type")
car_test[factors] <- lapply(car_test[factors], factor)

# levels(car_test$fuel.type)
```

Since EVs do not produce emissions, we set their emissions from N/A to 0
```{r}
# Set gas = 0 for EV
car_test$THC <- ifelse(is.na(car_test$THC) & car_test$fuel.type == "Electricity", 0, car_test$THC)
car_test$CO <- ifelse(is.na(car_test$CO) & car_test$fuel.type == "Electricity", 0, car_test$CO)
car_test$CO2 <- ifelse(is.na(car_test$CO2) & car_test$fuel.type == "Electricity" , 0, car_test$CO2)
car_test$NOx <- ifelse(is.na(car_test$NOx) & car_test$fuel.type == "Electricity" , 0, car_test$NOx)
car_test$PM <- ifelse(is.na(car_test$PM) & car_test$fuel.type == "Electricity" , 0, car_test$PM)
car_test$CH4 <- ifelse(is.na(car_test$CH4) & car_test$fuel.type == "Electricity" , 0, car_test$CH4)
car_test$N2O <- ifelse(is.na(car_test$N2O) & car_test$fuel.type == "Electricity", 0, car_test$N2O)

EV <- car_test[car_test$fuel.type=="Electricity", ] # check if gas variables set

# Set gas = 0 for HF
car_test$THC <- ifelse(is.na(car_test$THC) & car_test$fuel.type == "Hydrogen 5", 0, car_test$THC)
car_test$CO <- ifelse(is.na(car_test$CO) & car_test$fuel.type == "Hydrogen 5", 0, car_test$CO)
car_test$CO2 <- ifelse(is.na(car_test$CO2) & car_test$fuel.type == "Hydrogen 5" , 0, car_test$CO2)
car_test$NOx <- ifelse(is.na(car_test$NOx) & car_test$fuel.type == "Hydrogen 5" , 0, car_test$NOx)
car_test$PM <- ifelse(is.na(car_test$PM) & car_test$fuel.type == "Hydrogen 5" , 0, car_test$PM)
car_test$CH4 <- ifelse(is.na(car_test$CH4) & car_test$fuel.type == "Hydrogen 5" , 0, car_test$CH4)
car_test$N2O <- ifelse(is.na(car_test$N2O) & car_test$fuel.type == "Hydrogen 5", 0, car_test$N2O)

HF <- car_test[car_test$fuel.type=="Hydrogen 5", ] # check if gas variables set
```

For ease of analysis, we first partition into numeric and categorical variables.
Then visualize the missingness separately.
```{r}
library(dplyr)

car_test <- car_test %>% filter (!is.na(car_test$Vehicle.Manufacturer.Name))

# Split numeric and categorical components
numeric.car_test <- car_test %>% select_if(is.numeric)

numeric_variables <- sapply(car_test, is.numeric)
cat.car_test <- car_test[!numeric_variables]

# Install package "finalfit"

library(finalfit) # library for identifying and handling missing data
numeric.car_test %>%
    missing_plot() # Visualize the scope of missingness of numeric
# Among the gases, N20 and CH4 are weird, though PM is justified
# PM may be MNAR

cat.car_test %>%
    missing_plot() # Scope of missingness of categorical

table(car_test$Aftertreatment.Device.Cd)
table(car_test$aftertreatment)
```

### (Misc.) Analysis of Fuel Economy

```{r}
# Inspect response variable
hist(numeric.car_test$RND_ADJ_FE)
summary(numeric.car_test$RND_ADJ_FE)

# There is an observation of 10,000 MPG. Let's isolate it
out <- car_test[car_test$RND_ADJ_FE > 50, ]


car_test <- car_test[car_test$RND_ADJ_FE < 200, ] 
# the observations with FE > 200, being high consumption gas cars, does not make sense.
```
## Missing Data Analysis

### Missingness, grouped by fuel type CD

 - 19: Federal Cert Diesel 7-15 PPM Sulfur
 - 26: Cold CO Regular (Tier 2)
 - 27: Cold CO Premium (Tier 2)
 - 38: E85 (85% Ethanol 15% EPA Unleaded Gasoline)
 - 39: Tier 3 E10 Regular Gasoline (9 RVP @Low Alt.)
 - 50: Hydrogen 5 *(non-gas)*
 - 61: Tier 2 Cert Gasoline
 - 62: Electricity *(non-gas)*
 
> For Test Fuel Type CD == 62, set gas values to 0

Missingness between fuel type and gas
```{r}
library(naniar) # another missingdata viz library

# Dataframe with fuel type code and each gas emission variable
fuel_gas <- data.frame(car_test$fuel.type, car_test$CO, car_test$CO2, car_test$THC, car_test$N2O, car_test$CH4, car_test$NOx, car_test$PM)
colnames(fuel_gas)[1] <- "fuel.type" #rename fuel type
fg.mat <- fuel_gas %>% group_by(fuel.type) %>% miss_var_summary() #matrix of missing gases, grouped by fuel type

table(fuel_gas$fuel.type) # about 81.9% are Tier 2 Gas
```
We want an impression of what cars utilize fuel types besides Type 2 Gas

```{r}
coldco_veh <- car_test %>%
    filter(fuel.type %in% c("Cold CO Premium (Tier 2)","Cold CO Regular (Tier 2)"))
```

```{r}
vis_miss(fuel_gas, cluster = TRUE) # Pattern might be because of EV. We set equal 0 for EV.
vis_miss(fuel_gas, sort_miss = TRUE) # in descending order
vis_miss(car_test, sort_miss = TRUE)


gg_miss_var(fuel_gas, facet = fuel.type) # Proportionally, 26, 61 (Tier 2 Gas) and finally 62 (EV) have most missing, grouped by fuel type
```
```{r}
gg_miss_var(car_test) #overall proportionality of missing numeric variables
```

```{r}
PM.NA <- subset(car_test, !is.na(car_test$PM))
table(PM.NA$fuel.type) # speculate that PM is MAR

n2o.NA <- subset(car_test, is.na(car_test$N2O))
table(n2o.NA$fuel.type)

miss_var_summary(car_test)
```

> Address missing values, based on the three types of missing data
- Missing completely at random (MCAR)
- Missing at random (MAR)
- Missing not at random (MNAR)

In this last part of data cleaning, we make the decision to drop the 'FE Bags' due to the lack of patterns to their missingness, thus it is safe to assume that they are MCAR.

We also remove EVs and HF vehicles as they do not contribute to emissions.

```{r}
car_test <- car_test[, !names(car_test) %in% c("FE.Bag.4","FE.Bag.3","FE.Bag.2","FE.Bag.1")]

car_test_filter <- car_test[car_test$fuel.type != "Electricity", ]
car_test_filter <- car_test_filter[car_test_filter$fuel.type != "Hydrogen 5", ]
levels(car_test_filter$fuel.type)

car_test_filter$fuel.type <- droplevels(car_test_filter$fuel.type) #drop unused factor levels, ie electricity and hydrogen
levels(car_test_filter$fuel.type)

vis_miss(car_test_filter, cluster = TRUE)
# from the above visual, let's delete all observations missing vehicle
```

```{r}
# drop observations that do not have vehicle model 
car_test_filter <- car_test_filter[complete.cases(car_test_filter$Vehicle.Manufacturer.Name), ]

vis_miss(car_test_filter, cluster = F)
```
There are two distinct clusters to missingness. The first obvious cluster concerns gases, which comprise majority of the missing data. The next cluster, though marginal, concerns "Rotors and Cylinders", "DT Ratings" and "Aftertreatment".

```{r}
vis_miss(car_test_filter[,c("X..of.Cylinders.and.Rotors","DT.Inertia.Work.Ratio.Rating", "DT.Absolute.Speed.Change.Ratg", "DT.Energy.Economy.Rating")], cluster = T)
```

PM, CH4 and N2O form a major common cluster of missingness. Let's dive deeper into these variables and note their distributions

```{r}
library(ggplot2)
sel_col <- c("THC", "CO", "CO2", "NOx", "PM", "CH4", "N2O")

hist_plots <- list()

for (var in sel_col) {
    hist_plots[[var]] <- ggplot(car_test_filter, aes_string(x = var)) +
    geom_histogram() +
    labs(title = var) +
    theme_minimal()
}

grid <- do.call(gridExtra::grid.arrange, c(hist_plots, ncol = 2))
grid
```

Apart from CO2, our gas variables are heavily right skewed. However, PM and N2O are concerning because most of their more than 75% of their data is missing. There is the possibility that PM values are dependent on N2O. 

## Multiple Imputation

For multiple imputation models the goal is to use as much information as you have in order to obtain the estimates required to complete any missing data, on the condition that the missing data is 'missing at random', meaning that the missingness is related to the observed data. 
With this approach, rather than replacing missing values with the mean or median, we use the distribution of the observed data/variables to estimate multiple possible values for the data points. This allows us to account for the uncertainty around the true value, and obtain approximately unbiased estimates. 

The quickpred, under mice(), function allows us to view which variables will be used as the prior for imputing the missing values, for a particular row in the matrix. By modifying this matrix, we can determine what relevant information goes into the imputation.

However, because we do not know the causes of missingness, we can best go about screening the prior information by correlation coefficients.

The mice() library also automatically selects, on an iteratively univariate basis, the method of imputation

```{r}
library(mice)
# enforce minimum correlation coefficient to imputation variable of 0.4
# variable must have at least 50% present data
var.sel <- quickpred(car_test_filter, mincor = 0.3, minpuc = 0.5)
```



```{r}
# mcar_test(fuel_gas) # reject H0 i.e. p-value<alpha implies data is not MCAR, thus MAR. There is relation - is observed/missing

imp.data <- mice(data = car_test_filter, predictorMatrix = var.sel, m=5, maxit=10, seed = 123, print = FALSE)


# imp.datasets <- complete(imp.data, "long")  # combine all imputed sets
# mice detects multicollinearity automatically. Try quickpred() on car_test_filter
```

```{r}
tail(imp.data$loggedEvents, 20)

```

```{r}
# Check for nonconvergence, ie. all plots are erratic
# this ensures unbiased estimates achieved
plot(imp.data)
```
We note that "PM" and "DT variables" are convergent. Improve with more iterations



```{r}
# Extend number of iterations
imp.more <- mice.mids(imp.data, maxit = 30, print = F)
plot(imp.more)
```
"PM" and "DT Variables" still appear to be problematic, to no surprise. However, the imputation results for the rest of the predictors look great. We take special care in using "PM" and the "DT Variables" for the rest of the analyses.


Now we wish to choose our variables for linear regression based on correlation.
We pool the imputations, average them out by variable and calculate the correlation coefficients to CO2 correspondingly.

```{r}
ave <- imp.more %>%
  mice::complete("long") %>%
  select_if(is.numeric) %>%
  group_by(.id) %>%
  summarise_all(.funs = mean)

head(ave)
```

```{r}
cor <- ave %>%
    cor() %>%
    round(digits=2) 

cor.co2 <- cor[,"CO2"] %>%
    na.omit() %>%
    sort(decreasing = T)

cor.co2.df <- data.frame(values = cor.co2)
head(cor.co2.df)
```
Here we can select the numerical variables most correlated (coefficient of at least 0.4) to CO2 for use in our model.

Now we make a list of all our categorical variables, select numerics and apply stepwise regression to choose the best model (variable selection).

Given the large number of predictors, stepwise regression takes considerable time to run

```{r, include=FALSE}
scope <- list(upper = ~ Rated.Horsepower + Test.Veh.Displacement..L. + X..of.Cylinders.and.Rotors + NOx + Equivalent.Test.Weight..lbs.. + CH4 + Target.Coef.A..lbf. + CO + X..of.Gears + Represented.Test.Veh.Model + Vehicle.Type + trans + trans.lockup + drive.sys + trans.overdrive + fuel.type + aftertreatment,
              lower = ~1)
expr <- expression (f1 <- lm(CO2 ~ 1),
                    f2 <- step(f1, scope=scope))
fit <- with(imp.more, expr)
```
Count how many times each variable was selected:
```{r}
formulas <- lapply(fit$analyses, formula) # extract fitted model formulas
terms <- lapply(formulas, terms) # decompose model formulas into pieces
votes <- unlist(lapply(terms, labels)) # extract names of variables included in all models
table(votes) # count no. of time each variable in the 5 imputations
```
From the table, these predictors are always included:
- CH4
- Equiv. Test Weight
- CO
- Fuel type
- # of Cylinders/Rotors
- NOx
- Target Coefficient A (Dyno Reading)
- # of Gears
- drive.sys

We want to test the following predictors(that appear at least in 3 imputations), by nested model tests, if they are statistically significant:
- vehicle model
- vehicle displacement
- transmission lockup



```{r}
fit.without.vm <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys))

fit.with.vm <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys + Represented.Test.Veh.Model))

D1(fit.with.vm,fit.without.vm)
```
The small p-value yields that the Wald test is significant, thus we keep "Represented Test Vehicle Model" in the model.

Test for "Test Vehicle Displacement"
```{r}
fit.with.vd <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys + Represented.Test.Veh.Model + Test.Veh.Displacement..L.))

fit.without.vd <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys + Represented.Test.Veh.Model))

D1(fit.with.vd,fit.without.vd)
```
In this instance, our p-value is large, thus we drop test vehicle displacement

Test for "Transmission Lockup"
```{r}
fit.with.tl <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys + Represented.Test.Veh.Model + trans.lockup))

fit.without.tl <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys + Represented.Test.Veh.Model)) 

D1(fit.with.tl, fit.without.tl)
```
Similarly, we drop "Transmission Lockup" from the model.

## Multiple Regression Model

Fit the linear model (w/. test veh model) [complicated model, multinomial nature of "test veh model"]

```{r}
fit1.lm <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys + Represented.Test.Veh.Model))

est1.lm <- pool(fit1.lm)
# summary(est1.lm)
```

Fit linear model (w/o. test veh model)
```{r}
fit1.lm.wo <- with(imp.more, lm(CO2 ~ CH4 + Equivalent.Test.Weight..lbs.. + CO + fuel.type + X..of.Cylinders.and.Rotors + NOx + Target.Coef.A..lbf. + X..of.Gears + drive.sys))

est1.lm.wo <- pool(fit1.lm.wo)
# summary(est1.lm.wo)
```

Compare R-squared
```{r}
pool.r.squared(fit1.lm)
```

```{r}
pool.r.squared(fit1.lm.wo)
```


We thus have a model (though extremely complex) that accounts for 77.7% of the variation in CO2.

With the methodology of mice(), there are currently no available ways to carry out regression model diagnostics to assess the quality of fit, besides our coefficient of determination. 

Instead, there exists diagnostics to check MAR, MNAR and MCAR assumptions to assess the fit of the imputation model on missing data, such as the following:

```{r}
stripplot(imp.more, CH4~.imp, pch=20, cex=2)
```

```{r}
densityplot(imp.more, ~CO | .imp)
# distribution of variable (densities) separated by imputed (red) and original observed (blue).

bwplot(imp.more, CO ~.imp)
```
